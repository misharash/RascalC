{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Aperiodic Data and Jackknifes\n",
    "\n",
    "We present a basic example of the use of the RascalC Python wrapper for a single field, computing the 2PCF in $(r,\\mu)$ bins, and calibrating for the non-Gaussianity parameter using jackknifes.\n",
    "\n",
    "Here, we compute the covariance matrix for a single [QPM mock](https://arxiv.org/pdf/1309.5532.pdf) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies\n",
    "\n",
    "You need to install the `RascalC` Python library to run this notebook.\n",
    "It can be done via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install https://github.com/misharash/RascalC.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code requires [`pycorr`](https://github.com/cosmodesi/pycorr) to deal with pair counts and data correlation function estimators.\n",
    "To compute pair counts of catalogs (which is part of this tutorial), you need a [custom version of `Corrfunc`](https://github.com/adematti/Corrfunc) (see also [`pycorr` installation instructions](https://py2pcf.readthedocs.io/en/latest/user/building.html)).\n",
    "Both can be installed quickly via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install 'git+https://github.com/cosmodesi/pycorr#egg=pycorr[corrfunc]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More common requirements are `astropy` and `scikit-learn`.\n",
    "They can be installed through Anaconda (`conda`) if you have it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install astropy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, install via `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install astropy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the input data\n",
    "\n",
    "The following cells download the publicly available mock galaxy and random catalogs for [BOSS DR12](https://www.sdss3.org/science/boss_publications.php) from the [SDSS website](https://sdss.org/).\n",
    "If you already have `mock_galaxy_DR12_CMASS_N_QPM_0001.rdzw` and `mock_random_DR12_CMASS_N_50x1.rdzw` files, please go ahead to the next section.\n",
    "\n",
    "Beware that the archive with the mock data is about 12 gigabytes, although it can be removed after extracting just one catalog of about 37 megabytes.\n",
    "The random catalog is about 1.5 gigabytes uncompressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-30 11:55:58--  https://data.sdss.org/sas/dr12/boss/lss/qpm_mocks/mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz\n",
      "Resolving data.sdss.org (data.sdss.org)... 155.101.19.31\n",
      "Connecting to data.sdss.org (data.sdss.org)|155.101.19.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12482301869 (12G) [application/octet-stream]\n",
      "Saving to: ‘mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz’\n",
      "\n",
      "mock_galaxy_DR12_CM 100%[===================>]  11.62G  75.9MB/s    in 3m 11s  \n",
      "\n",
      "2024-04-30 11:59:10 (62.2 MB/s) - ‘mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz’ saved [12482301869/12482301869]\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! wget https://data.sdss.org/sas/dr12/boss/lss/qpm_mocks/mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz # download the archive with all mock galaxy catalogs (≈12 GB)\n",
    "! tar -xzvf mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz mock_galaxy_DR12_CMASS_N_QPM_0001.rdzw # unpack one catalog (≈37 MB)\n",
    "! rm mock_galaxy_DR12_CMASS_N_QPM_allmocks.tar.gz # remove the big (≈12 GB) archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-30 12:01:32--  https://data.sdss.org/sas/dr12/boss/lss/qpm_mocks/mock_random_DR12_CMASS_N_50x1.rdzw.gz\n",
      "Resolving data.sdss.org (data.sdss.org)... 155.101.19.31\n",
      "Connecting to data.sdss.org (data.sdss.org)|155.101.19.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 600910232 (573M) [application/octet-stream]\n",
      "Saving to: ‘mock_random_DR12_CMASS_N_50x1.rdzw.gz’\n",
      "\n",
      "mock_random_DR12_CM 100%[===================>] 573.07M  54.2MB/s    in 9.7s    \n",
      "\n",
      "2024-04-30 12:01:41 (59.2 MB/s) - ‘mock_random_DR12_CMASS_N_50x1.rdzw.gz’ saved [600910232/600910232]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://data.sdss.org/sas/dr12/boss/lss/qpm_mocks/mock_random_DR12_CMASS_N_50x1.rdzw.gz # download the compressed random catalog (≈600 MB)\n",
    "! gunzip mock_random_DR12_CMASS_N_50x1.rdzw.gz # uncompress (≈1.5 GB), typically deleting the compressed version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "galaxies_filename = \"mock_galaxy_DR12_CMASS_N_QPM_0001.rdzw\"\n",
    "randoms_filename = \"mock_random_DR12_CMASS_N_50x1.rdzw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the original files: text with RA, DEC, Z (redshift) and weight columns.\n",
    "This, and many of the next cells, may take about 10 seconds because of the large number of randoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "galaxies = Table(np.loadtxt(galaxies_filename, usecols = range(4)), names = [\"RA\", \"DEC\", \"Z\", \"WEIGHT\"]) # ignore the last column, not sure what it is\n",
    "randoms = Table(np.loadtxt(randoms_filename, usecols = range(4)), names = [\"RA\", \"DEC\", \"Z\", \"WEIGHT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the comoving distance within the fiducial (grid) cosmology. Here we use a utility function from the RascalC library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from RascalC.pre_process.convert_to_xyz import comoving_distance_Mpch\n",
    "Omega_m = 0.29; Omega_k = 0; w_DE = -1 # density parameters of matter and curvature, and the equation-of-state parameter of dark energy\n",
    "galaxies[\"comov_dist\"] = comoving_distance_Mpch(galaxies[\"Z\"], Omega_m, Omega_k, w_DE)\n",
    "randoms[\"comov_dist\"] = comoving_distance_Mpch(randoms[\"Z\"], Omega_m, Omega_k, w_DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a utility function for position formatting that will be useful on several more occasions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rdd_positions(catalog: Table) -> tuple[np.ndarray[float]]: # utility function to format positions from a catalog\n",
    "    return (catalog[\"RA\"], catalog[\"DEC\"], catalog[\"comov_dist\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign jackknife regions to both galaxies and randoms.\n",
    "\n",
    "The `get_subsampler_xirunpc` function generates a $K$-means subsampler from `sklearn` under the rug through a `pycorr` interface, ensuring that it is run single-threaded.\n",
    "If you call it in your own way, beware that it might run multi-threaded if `OMP_` environment variables are set, and that is known to impede the performance of the main `RascalC` covariance computation later (due to OpenMP limitations).\n",
    "\n",
    "$K$-means is nice in that it can generate a fixed number of regions of similar size with realistic survey geometry.\n",
    "(However, it is not without issues, e.g. it does not guarantee similar completeness patterns that may affect the shot-noise rescaling.)\n",
    "Previously, jackknife region numbers were assigned as `healpix` pixels (with number controlled by `NSIDE` variable), which is simpler, but less balanced and flexible.\n",
    "In cubic/rectangular boxes, box subsamplers from `pycorr` may be useful.\n",
    "If you have better ideas, feel free to use them and perhaps share with the code authors if they work out well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from RascalC.pre_process.create_jackknives_pycorr import get_subsampler_xirunpc\n",
    "n_jack = 60 # number of regions\n",
    "subsampler = get_subsampler_xirunpc(get_rdd_positions(galaxies), n_jack, position_type = \"rdd\") # \"rdd\" means RA, DEC in degrees and then distance (corresponding to pycorr)\n",
    "galaxies[\"JACK\"] = subsampler.label(get_rdd_positions(galaxies), position_type = \"rdd\")\n",
    "randoms[\"JACK\"] = subsampler.label(get_rdd_positions(randoms), position_type = \"rdd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a smaller subset of randoms to make pair counting and `RascalC` importance sampling more feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_randoms = 10 # how many times the number of galaxies should the number of randoms be; the total number of randoms is ≈50x the number of galaxies\n",
    "np.random.seed(42) # for reproducibility\n",
    "randoms_subset = randoms[np.random.choice(len(randoms), x_randoms * len(galaxies), replace = False, p = randoms[\"WEIGHT\"] / np.sum(randoms[\"WEIGHT\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair counts and correlation functions with [`pycorr`](https://github.com/cosmodesi/pycorr)\n",
    "\n",
    "In addition to the galaxy and randoms catalogs, `RascalC` requires the random counts and correlation functions.\n",
    "We use [`pycorr`](https://github.com/cosmodesi/pycorr) — a wrapper over the fast pair-counting engine `Corrfunc` that saves all the counts and allows to re-bin.\n",
    "So it can nicely do in one go what used to require several scripts in the legacy version of this tutorial.\n",
    "\n",
    "We remind you to make sure your current Python environment has [the custom version of `Corrfunc`](https://github.com/cosmodesi/Corrfunc) as suggested for [`pycorr`](https://github.com/cosmodesi/pycorr) (see also [the Installing dependencies section](#Installing-dependencies) in the beginning of this notebook).\n",
    "\n",
    "Pair counting requires the same catalogs as the main `RascalC` covariance computation.\n",
    "To minimize the repetitions and/or avoid splitting in this tutorial, we decided to incorporate the `pycorr` run here.\n",
    "This required some extra tricks to avoid the OpenMP (multi-threading) interference, even more so to make this run safely in a Jupyter notebook (and not just in a script).\n",
    "\n",
    "In a \"production\" run, you might want to set up the `pycorr` pair counting separately.\n",
    "We typically do so, noting that it can be performed on GPU while the main covariance computation with `RascalC` proper requires CPU only.\n",
    "But it is **very important** to reproduce the pre-processing (including jackknife assignment) for `RascalC` inputs in the same way it was done for pair counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we choose whether to use full randoms or a smaller subset for pair counting.\n",
    "The latter is faster but a bit less precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# randoms_for_counts = randoms\n",
    "randoms_for_counts = randoms_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue by splitting the randoms into parts of roughly the same size as data.\n",
    "This gives high precision at fixed computing cost [(Keihänen et al 2019)](https://arxiv.org/abs/1905.01133)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting randoms into 10 parts\n"
     ]
    }
   ],
   "source": [
    "n_splits = int(np.rint(len(randoms_for_counts) / len(galaxies))) # the number of parts to split the randoms to\n",
    "print(f\"Splitting randoms into {n_splits} parts\")\n",
    "\n",
    "# split randoms into the desired number of parts randomly\n",
    "random_indices = np.arange(len(randoms_for_counts))\n",
    "np.random.seed(42) # for reproducibility\n",
    "np.random.shuffle(random_indices) # random shuffle in place\n",
    "random_parts = [randoms_for_counts[random_indices[i_random::n_splits]] for i_random in range(n_splits)] # quick way to produce parts of almost the same size\n",
    "\n",
    "# normalize the weights in each part — fluctuations in their sums may be a bit of a problem\n",
    "for i_random in range(n_splits): random_parts[i_random][\"WEIGHT\"] /= np.sum(random_parts[i_random][\"WEIGHT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and select settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycorr import TwoPointCorrelationFunction, setup_logging\n",
    "from tqdm import trange # nice progress bar\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# version for small-scale counts with concatenated randoms, worked too slow (also see below)\n",
    "n_threads = 64 # number of threads for pycorr computation\n",
    "split_above = 20 # Mpc/h. Below this, will use concatenated randoms. Above, will use split.\n",
    "s_max = 200 # maximal separation in Mpc/h\n",
    "n_mu = 200 # number of angular (µ) bins\n",
    "counts_filename = f\"allcounts_mock_galaxy_DR12_CMASS_N_QPM_0001_lin_njack{n_jack}_nran{n_splits}_split{split_above}.npy\" # filename to save counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_threads = 10 # number of threads for pycorr computation\n",
    "s_max = 200 # maximal separation in Mpc/h\n",
    "n_mu = 200 # number of angular (µ) bins\n",
    "counts_filename = f\"allcounts_mock_galaxy_DR12_CMASS_N_QPM_0001_lin_njack{n_jack}_nran{n_splits}_split{0}.npy\" # filename to save counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to compute the counts, using split randoms at larger separations."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# version where the small-scale counts are computed with concatenated randoms, that part worked incredibly slow with jackknives — much slower than the larger-scale split counts\n",
    "mu_edges = np.linspace(-1, 1, n_mu + 1) # make uniform µ bins between -1 and 1, or twice less bins between 0 and 1 after wrapping (will be done within RascalC wrapper)\n",
    "s_edges_all = (np.arange(split_above + 1), np.arange(split_above, s_max + 1)) # 1 Mpc/h wide separation bins from 0 to s_max Mpc/h, separated to concatenated/split random regions. Can be rebinned to any bin width that divides split_above and s_max\n",
    "\n",
    "def run_pair_counts(): # the code to run pycorr, needs to be invoked in a separate process from what will run RascalC then!\n",
    "    setup_logging()\n",
    "    results = []\n",
    "    # compute\n",
    "    for i_split_randoms, s_edges in enumerate(s_edges_all):\n",
    "        result = 0\n",
    "        D1D2 = None # to compute the data-data counts on the first go but not recompute then\n",
    "        for i_random in trange(n_splits if i_split_randoms else 1, desc=\"Computing counts with random part\"):\n",
    "            these_randoms = random_parts[i_random] if i_split_randoms else randoms_for_counts\n",
    "            tmp = TwoPointCorrelationFunction(mode = 'smu', edges = (s_edges, mu_edges),\n",
    "                                            data_positions1 = get_rdd_positions(galaxies), data_weights1 = galaxies[\"WEIGHT\"], data_samples1 = galaxies[\"JACK\"],\n",
    "                                            randoms_positions1 = get_rdd_positions(these_randoms), randoms_weights1 = these_randoms[\"WEIGHT\"], randoms_samples1 = these_randoms[\"JACK\"],\n",
    "                                            position_type = \"rdd\", engine = \"corrfunc\", D1D2 = D1D2, gpu = False, nthreads = n_threads)\n",
    "            # \"rdd\" means RA, DEC in degrees and then distance\n",
    "            D1D2 = tmp.D1D2 # once computed, becomes not None and will not be recomputed\n",
    "            result += tmp\n",
    "        results.append(result)\n",
    "    corr = results[0].concatenate_x(*results) # join the unsplit and split parts\n",
    "    corr.D1D2.attrs['nsplits'] = n_splits\n",
    "\n",
    "    corr.save(counts_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_edges = np.arange(s_max + 1) # 1 Mpc/h wide separation bins from 0 to s_max Mpc/h\n",
    "mu_edges = np.linspace(-1, 1, n_mu + 1) # make uniform µ bins between -1 and 1, or twice less bins between 0 and 1 after wrapping (will be done within RascalC wrapper)\n",
    "\n",
    "def run_pair_counts(): # the code to run pycorr, needs to be invoked in a separate process from what will run RascalC then!\n",
    "    setup_logging()\n",
    "    result = 0\n",
    "    D1D2 = None # to compute the data-data counts on the first go but not recompute then\n",
    "    for i_random in trange(n_splits, desc=\"Computing counts with random part\"):\n",
    "        these_randoms = random_parts[i_random]\n",
    "        tmp = TwoPointCorrelationFunction(mode = 'smu', edges = (s_edges, mu_edges),\n",
    "                                        data_positions1 = get_rdd_positions(galaxies), data_weights1 = galaxies[\"WEIGHT\"], data_samples1 = galaxies[\"JACK\"],\n",
    "                                        randoms_positions1 = get_rdd_positions(these_randoms), randoms_weights1 = these_randoms[\"WEIGHT\"], randoms_samples1 = these_randoms[\"JACK\"],\n",
    "                                        position_type = \"rdd\", engine = \"corrfunc\", D1D2 = D1D2, gpu = False, nthreads = n_threads)\n",
    "        # \"rdd\" means RA, DEC in degrees and then distance\n",
    "        D1D2 = tmp.D1D2 # once computed, becomes not None and will not be recomputed\n",
    "        result += tmp\n",
    "    result.D1D2.attrs['nsplits'] = n_splits\n",
    "\n",
    "    result.save(counts_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is a tricky part where we create a child process to run pair counts to avoid OpenMP multi-threading interference.\n",
    "\n",
    "The computation does take a while (about 10 minutes for me at NERSC login node; expect to see 1/10 progress in a few minutes) even with multi-threading (which I haven't managed to make work with `Corrfunc` in macOS yet).\n",
    "If you already have the counts saved into file, no need to run this cell again – they will be loaded later.\n",
    "\n",
    "It is **best not to interrupt the next cell** because it is rather hard to control the forked child process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child process ID 93491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing xi with random part: 100%|██████████| 10/10 [09:07<00:00, 54.73s/it]\n"
     ]
    }
   ],
   "source": [
    "child_pid = os.fork() # creates a new process at the same execution stage with access to all the data. Returns 0 in child process and non-zero child process ID in the original, parent process\n",
    "if not child_pid:\n",
    "    # new child process\n",
    "    print(f\"Child process ID {os.getpid()}\") # printing from the parent process may interfere with the progress bar\n",
    "    import traceback\n",
    "    try:\n",
    "        run_pair_counts()\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        os._exit(-1) # terminate the process with error\n",
    "    # in a script, would not need try-except and import traceback above. This is because script process is already terminated on error/exception with a non-zero exit code, in notebook it remains to hang around\n",
    "    os._exit(0) # terminate ok if no error occured\n",
    "else:\n",
    "    # original parent process\n",
    "    child_pid2, child_status = os.waitpid(child_pid, 0) # wait for the child process to terminate\n",
    "    if child_status: raise RuntimeError(f\"Child process exited with error (code {os.waitstatus_to_exitcode(child_status)}). See its traceback above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case the previous cell was interrupted**, the child process may remain hanging about, so **execute the following cell** to force it to terminate.\n",
    "(Unlikely to harm to execute it otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "os.kill(child_pid, signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should load the saved counts in the original process. You can continue from this step if you computed the counts before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcounts = TwoPointCorrelationFunction.load(counts_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance settings and computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mode = \"legendre_projected\" # Legendre multipoles projected from s,µ bins\n",
    "max_l = 4 # max multipole to compute the covariance for\n",
    "periodic_boxsize = None # not a periodic box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime and convergence parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_threads = 10\n",
    "N2 = 10 # number of secondary points sampled per primary random point\n",
    "N3 = 20 # number of tertiary points sampled per each secondary\n",
    "N4 = 40 # number of quaternary points sampled per each tertiary\n",
    "n_loops = 80 # must be divisible by n_threads\n",
    "loops_per_sample = 5 # must divide n_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remind that `RascalC` will be provided with only a subset of randoms here, `randoms_subset`.\n",
    "\n",
    "The convergence of covariance matrix integrals is determined by the number of 4-point configurations sampled, which is roughly `len(random_subset)*N2*N3*N4*n_loops`.\n",
    "\n",
    "The runtime is roughly proportional to the same number of 4-point configurations but divided by the number of threads: `len(random_subset)*N2*N3*N4*n_loops/n_thread`.\n",
    "* Different loops may take different time to complete due to random factors, so it is recommended to have the number of loops several times the number of threads.\n",
    "* It is not advisable to set either of `N2/3/4` too low, say `<5`, because then loops may become inefficient.\n",
    "\n",
    "Finally, `loops_per_sample` regulates how many loops are grouped into a distinct estimate of covariance matrices using a subset of sampled point configurations.\n",
    "The code then needs some (say 10-30) such independent subsamples to estimate the convergence (and inversion bias) of the covariance matrix, but saving too many increases disk usage and can slow down the calculation.\n",
    "A sample that is already saved can be reused (although this may be a bit tedious), otherwise there is no capability to restore the progress of `RascalC` after interruption/termination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we set the radial/separation binning of the covariance matrix by rebinning the counts. Here we leave the original number of angular bins – the covariance will be project into only a few (even) multipoles using all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cov = 4\n",
    "s_min_cov = 20\n",
    "s_max_cov = 200\n",
    "allcounts_rebinned_cov = allcounts[s_min_cov:s_max_cov:ds_cov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separation bin edges for the covariance will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.,  24.,  28.,  32.,  36.,  40.,  44.,  48.,  52.,  56.,  60.,\n",
       "        64.,  68.,  72.,  76.,  80.,  84.,  88.,  92.,  96., 100., 104.,\n",
       "       108., 112., 116., 120., 124., 128., 132., 136., 140., 144., 148.,\n",
       "       152., 156., 160., 164., 168., 172., 176., 180., 184., 188., 192.,\n",
       "       196., 200.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcounts_rebinned_cov.edges[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also rebin the pycorr counts into reasonable (typically a bit finer) bins for the input two-point correlation function.\n",
    "Here we also should reduce the number of angular ($\\mu$) bins, because `RascalC` takes the input 2PCF as a $\\xi(s,\\mu)$ table in any mode.\n",
    "\n",
    "It is also possible to generate a $\\xi(s,\\mu)$ table from theory and not from pycorr measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_xi = 2\n",
    "n_mu_xi = 20 # between µ = 0 and 1, i.e. after wrapping\n",
    "assert allcounts.wrap().shape[1] % n_mu_xi == 0, \"Counts not rebinnable to the desired number of angular bins\"\n",
    "allcounts_rebinned_xi = allcounts[::ds_xi, ::allcounts.wrap().shape[1] // n_mu_xi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,\n",
       "         22.,  24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,\n",
       "         44.,  46.,  48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,\n",
       "         66.,  68.,  70.,  72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,\n",
       "         88.,  90.,  92.,  94.,  96.,  98., 100., 102., 104., 106., 108.,\n",
       "        110., 112., 114., 116., 118., 120., 122., 124., 126., 128., 130.,\n",
       "        132., 134., 136., 138., 140., 142., 144., 146., 148., 150., 152.,\n",
       "        154., 156., 158., 160., 162., 164., 166., 168., 170., 172., 174.,\n",
       "        176., 178., 180., 182., 184., 186., 188., 190., 192., 194., 196.,\n",
       "        198., 200.]),\n",
       " array([-1.  , -0.95, -0.9 , -0.85, -0.8 , -0.75, -0.7 , -0.65, -0.6 ,\n",
       "        -0.55, -0.5 , -0.45, -0.4 , -0.35, -0.3 , -0.25, -0.2 , -0.15,\n",
       "        -0.1 , -0.05,  0.  ,  0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,\n",
       "         0.35,  0.4 ,  0.45,  0.5 ,  0.55,  0.6 ,  0.65,  0.7 ,  0.75,\n",
       "         0.8 ,  0.85,  0.9 ,  0.95,  1.  ])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcounts_rebinned_xi.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output and temporary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outdir = \"out\"\n",
    "tmpdir = \"tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The main covariance computation with `RascalC` interface\n",
    "\n",
    "You should see several `Computing correlation function iteration` messages in a few minutes.\n",
    "The whole computation will take a while (about 5 hours for me)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: legendre_projected\n",
      "Periodic box: False\n",
      "Jackknife: True\n",
      "Number of tracers: 1\n",
      "Normalizing weights and weighted counts: True\n",
      "2024-05-01 07:29:32.927631\n",
      "Wrapping pycorr_allcounts_11 to µ>=0\n",
      "Number(s) of data galaxies: (642051,)\n",
      "Wrapping xi_table_11 to µ>=0\n",
      "2024-05-01 07:30:03.022447\n",
      "Launching the C++ code with command: env OMP_PROC_BIND=spread OMP_PLACES=threads /global/common/software/desi/users/mrash/RascalC/RascalC/bin/cov.legendre_projected_jackknife -output out/ -nside 301 -rescale 1 -nthread 10 -maxloops 80 -loopspersample 5 -N2 10 -N3 20 -N4 40 -xicut 250 -binfile out/radial_binning_cov.csv -binfile_cf out/radial_binning_corr.csv -mbin_cf 20 -cf_loops 10 -in tmp/0.txt -norm 642051 -cor out/xi/xi_11.dat -max_l 4 -mu_bin_legendre_file out/weights/mu_bin_legendre_factors_m100_l4.txt -RRbin out/weights/binned_pair_counts_n45_m100_j60_11.dat -mbin 100 -jackknife out/weights/jackknife_weights_n45_m100_j60_11.dat\n",
      "\n",
      "Mu bin Legendre factors file 'out/weights/mu_bin_legendre_factors_m100_l4.txt'\n",
      "Read in mu bin Legendre factors successfully.\n",
      "\n",
      "\n",
      "Using a single set of tracer particles\n",
      "\n",
      "Reading radial binning file 'out/radial_binning_cov.csv'\n",
      "\n",
      "# Found 45 radial bins in the file\n",
      "Read in 45 radial bins in range (20, 200) successfully.\n",
      "\n",
      "Reading radial correlation function binning file 'out/radial_binning_corr.csv'\n",
      "\n",
      "# Found 100 radial bins in the correlation function binning file\n",
      "Read in 100 radial bins in range (0, 200) successfully.\n",
      "Grid = 301\n",
      "Maximum Radius = 2.00000e+02\n",
      "Radial Bins = 45\n",
      "Radial Binning = {20.00000, 200.00000} over 45 bins (user-defined bin widths) \n",
      "Mu Bins = 100\n",
      "Mu Binning = {0.00000, 1.00000, 0.01000}\n",
      "Number of galaxies = 6.42051e+05\n",
      "Maximum number of integration loops = 80\n",
      "Number of output subsamples = 16\n",
      "Output directory: 'out/'\n",
      "\n",
      "Reading RR bin count file 'out/weights/binned_pair_counts_n45_m100_j60_11.dat'\n",
      "Read in RR pair counts successfully.\n",
      "\n",
      "Reading jackknife file 'out/weights/jackknife_weights_n45_m100_j60_11.dat'\n",
      "\n",
      "# Found 60 non-empty jackknives in the file\n",
      "Read in jackknife weights successfully.\n",
      "Computed product weights successfully.\n",
      "# Found 6420510 particles from tmp/0.txt\n",
      "# Rescaling input positions by factor 1.000000\n",
      "# Done reading the particles\n",
      "# Range of x positions are -1761.41 to -107.53\n",
      "# Range of y positions are -1622.78 to 1539.80\n",
      "# Range of z positions are -110.03 to 1640.25\n",
      "# Setting non-periodic box-size to {1665.30,3169.04,1752.29}\n",
      "# Allocating 318.400 MB of particles\n",
      "# Allocating 73.516 MB of cells\n",
      "\n",
      "There are 1521598 filled cells compared with 4817970 total cells.\n",
      "\n",
      " RANDOM CATALOG 1 DIAGNOSTICS:\n",
      "Average number of particles per grid cell =   4.22\n",
      "Average number of particles per max_radius ball = 23266.03\n",
      "# Done gridding the particles\n",
      "# 6420510 particles in use, 6420510 with positive weight\n",
      "# Weights: Positive particles sum to 1.000000\n",
      "#          Negative particles sum to 0.000000\n",
      "Final grid = 301\n",
      "Box Size = {1.66530e+03,3.16904e+03,1.75229e+03}\n",
      "Max Radius in Grid Units = 1.60932e+01\n",
      "Rescaling RR pair counts by a factor (N_gal_1/N_rand_1)*(N_gal2/N_rand2) = 1.0e-02\n",
      "# Found 100 radial and 20 mu bins in out/xi/xi_11.dat\n",
      "\n",
      "# Computing the probability grid\n",
      "Number of Boxes in Probability Grid: 117649\n",
      "# Probability grid computation complete\n",
      "\n",
      "Number of Boxes in Probability Grid: 456533\n",
      "\n",
      "Refining correlation function 1 of 1.\n",
      "# Computing correlation function iteration 1 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 884 in correlation function bin 5 (radial 0, angular 5). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 2 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 852 in correlation function bin 5 (radial 0, angular 5). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 3 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 838 in correlation function bin 0 (radial 0, angular 0). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 4 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 889 in correlation function bin 0 (radial 0, angular 0). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 5 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 887 in correlation function bin 9 (radial 0, angular 9). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 6 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 850 in correlation function bin 8 (radial 0, angular 8). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 7 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 812 in correlation function bin 14 (radial 0, angular 14). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 8 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 857 in correlation function bin 3 (radial 0, angular 3). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 9 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 875 in correlation function bin 2 (radial 0, angular 2). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "# Computing correlation function iteration 10 of 10 on 10 threads.\n",
      "Smallest number of pairs sampled is 874 in correlation function bin 14 (radial 0, angular 14). If the number is not large, consider increasing N2 and/or number of integration loops, or using coarser correlation function binning, or providing denser randoms.\n",
      "\n",
      "# Computing the probability grid\n",
      "Number of Boxes in Probability Grid: 117649\n",
      "# Probability grid computation complete\n",
      "\n",
      "Number of Boxes in Probability Grid: 456533\n",
      "Computed relevant product weights\n",
      "Init time: 0.001927 s\n",
      "# 1st grid filled cells: 1521598\n",
      "# All 1st grid points in use: 6420510\n",
      "# Max points in one cell in grid 119\n",
      "# Starting integral computation 1 of 1 on 10 threads.\n",
      "Integral 1 of 1, iteration 6 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 7 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 4 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 3 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 9 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 10 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 5 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 2 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 8 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 1 of 80 on thread 0 completed\n",
      "\n",
      "Finished 10 integral loops of 80 after 2246 s. Estimated time left:  04:22:02 hms, i.e. 15722 s.\n",
      "Frobenius percent difference after 10 loops is 0.145 (C2), 4.832 (C3), 1.934 (C4)\n",
      "Frobenius jackknife percent difference after 10 loops is 0.137 (C2j), 5.248 (C3j), 2.669 (C4j)\n",
      "Integral 1 of 1, iteration 11 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 13 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 14 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 12 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 15 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 16 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 18 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 17 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 19 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 20 of 80 on thread 0 completed\n",
      "\n",
      "Finished 20 integral loops of 80 after 4478 s. Estimated time left:  03:43:54 hms, i.e. 13434 s.\n",
      "Frobenius percent difference after 20 loops is 0.076 (C2), 1.766 (C3), 0.666 (C4)\n",
      "Frobenius jackknife percent difference after 20 loops is 0.078 (C2j), 1.895 (C3j), 0.974 (C4j)\n",
      "Integral 1 of 1, iteration 21 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 24 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 23 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 22 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 26 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 25 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 27 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 28 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 29 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 30 of 80 on thread 0 completed\n",
      "\n",
      "Finished 30 integral loops of 80 after 6718 s. Estimated time left:  03:06:36 hms, i.e. 11196 s.\n",
      "Frobenius percent difference after 30 loops is 0.029 (C2), 1.014 (C3), 0.444 (C4)\n",
      "Frobenius jackknife percent difference after 30 loops is 0.029 (C2j), 1.093 (C3j), 0.628 (C4j)\n",
      "Integral 1 of 1, iteration 31 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 32 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 34 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 33 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 35 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 36 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 37 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 38 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 39 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 40 of 80 on thread 0 completed\n",
      "\n",
      "Finished 40 integral loops of 80 after 8952 s. Estimated time left:  02:29:12 hms, i.e. 8952 s.\n",
      "Frobenius percent difference after 40 loops is 0.026 (C2), 0.721 (C3), 0.305 (C4)\n",
      "Frobenius jackknife percent difference after 40 loops is 0.026 (C2j), 0.782 (C3j), 0.422 (C4j)\n",
      "Integral 1 of 1, iteration 41 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 42 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 43 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 44 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 46 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 45 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 47 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 48 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 49 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 50 of 80 on thread 0 completed\n",
      "\n",
      "Finished 50 integral loops of 80 after 11210 s. Estimated time left:  01:52:06 hms, i.e. 6726 s.\n",
      "Frobenius percent difference after 50 loops is 0.015 (C2), 0.558 (C3), 0.236 (C4)\n",
      "Frobenius jackknife percent difference after 50 loops is 0.016 (C2j), 0.610 (C3j), 0.331 (C4j)\n",
      "Integral 1 of 1, iteration 51 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 52 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 53 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 54 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 55 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 56 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 57 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 58 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 59 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 60 of 80 on thread 0 completed\n",
      "\n",
      "Finished 60 integral loops of 80 after 13398 s. Estimated time left:  01:14:26 hms, i.e. 4466 s.\n",
      "Frobenius percent difference after 60 loops is 0.023 (C2), 0.577 (C3), 0.190 (C4)\n",
      "Frobenius jackknife percent difference after 60 loops is 0.024 (C2j), 0.648 (C3j), 0.266 (C4j)\n",
      "Integral 1 of 1, iteration 61 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 62 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 63 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 64 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 65 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 66 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 67 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 68 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 69 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 70 of 80 on thread 0 completed\n",
      "\n",
      "Finished 70 integral loops of 80 after 15558 s. Estimated time left:  00:37:02 hms, i.e. 2222 s.\n",
      "Frobenius percent difference after 70 loops is 0.019 (C2), 0.384 (C3), 0.159 (C4)\n",
      "Frobenius jackknife percent difference after 70 loops is 0.020 (C2j), 0.413 (C3j), 0.227 (C4j)\n",
      "Integral 1 of 1, iteration 71 of 80 on thread 1 completed\n",
      "Integral 1 of 1, iteration 72 of 80 on thread 2 completed\n",
      "Integral 1 of 1, iteration 73 of 80 on thread 4 completed\n",
      "Integral 1 of 1, iteration 74 of 80 on thread 3 completed\n",
      "Integral 1 of 1, iteration 75 of 80 on thread 9 completed\n",
      "Integral 1 of 1, iteration 76 of 80 on thread 7 completed\n",
      "Integral 1 of 1, iteration 77 of 80 on thread 8 completed\n",
      "Integral 1 of 1, iteration 78 of 80 on thread 6 completed\n",
      "Integral 1 of 1, iteration 79 of 80 on thread 5 completed\n",
      "Integral 1 of 1, iteration 80 of 80 on thread 0 completed\n",
      "\n",
      "Finished 80 integral loops of 80 after 17687 s. Estimated time left:  00:00:00 hms, i.e. 0 s.\n",
      "Frobenius percent difference after 80 loops is 0.014 (C2), 0.692 (C3), 0.140 (C4)\n",
      "Frobenius jackknife percent difference after 80 loops is 0.013 (C2j), 0.812 (C3j), 0.200 (C4j)\n",
      "\n",
      "\n",
      "INTEGRAL 1 OF 1 COMPLETE\n",
      "Loop 0 time: 2246 s, i.e. 00:37:26 hms\n",
      "Loop 1 time: 2142 s, i.e. 00:35:42 hms\n",
      "Loop 2 time: 2028 s, i.e. 00:33:48 hms\n",
      "Loop 3 time: 2028 s, i.e. 00:33:48 hms\n",
      "Loop 4 time: 2123 s, i.e. 00:35:23 hms\n",
      "Loop 5 time: 1952 s, i.e. 00:32:32 hms\n",
      "Loop 6 time: 2010 s, i.e. 00:33:30 hms\n",
      "Loop 7 time: 2188 s, i.e. 00:36:28 hms\n",
      "Loop 8 time: 2055 s, i.e. 00:34:15 hms\n",
      "Loop 9 time: 2081 s, i.e. 00:34:41 hms\n",
      "Loop 10 time: 2007 s, i.e. 00:33:27 hms\n",
      "Loop 11 time: 2062 s, i.e. 00:34:22 hms\n",
      "Loop 12 time: 2014 s, i.e. 00:33:34 hms\n",
      "Loop 13 time: 2042 s, i.e. 00:34:02 hms\n",
      "Loop 14 time: 2110 s, i.e. 00:35:10 hms\n",
      "Loop 15 time: 2084 s, i.e. 00:34:44 hms\n",
      "Loop 16 time: 2160 s, i.e. 00:36:00 hms\n",
      "Loop 17 time: 2109 s, i.e. 00:35:09 hms\n",
      "Loop 18 time: 2113 s, i.e. 00:35:13 hms\n",
      "Loop 19 time: 2232 s, i.e. 00:37:12 hms\n",
      "Loop 20 time: 1962 s, i.e. 00:32:42 hms\n",
      "Loop 21 time: 2065 s, i.e. 00:34:25 hms\n",
      "Loop 22 time: 2029 s, i.e. 00:33:49 hms\n",
      "Loop 23 time: 2006 s, i.e. 00:33:26 hms\n",
      "Loop 24 time: 2141 s, i.e. 00:35:41 hms\n",
      "Loop 25 time: 2098 s, i.e. 00:34:58 hms\n",
      "Loop 26 time: 2115 s, i.e. 00:35:15 hms\n",
      "Loop 27 time: 2166 s, i.e. 00:36:06 hms\n",
      "Loop 28 time: 2202 s, i.e. 00:36:42 hms\n",
      "Loop 29 time: 2239 s, i.e. 00:37:19 hms\n",
      "Loop 30 time: 1934 s, i.e. 00:32:14 hms\n",
      "Loop 31 time: 2000 s, i.e. 00:33:20 hms\n",
      "Loop 32 time: 2120 s, i.e. 00:35:20 hms\n",
      "Loop 33 time: 2023 s, i.e. 00:33:43 hms\n",
      "Loop 34 time: 2129 s, i.e. 00:35:29 hms\n",
      "Loop 35 time: 2105 s, i.e. 00:35:05 hms\n",
      "Loop 36 time: 2118 s, i.e. 00:35:18 hms\n",
      "Loop 37 time: 2134 s, i.e. 00:35:34 hms\n",
      "Loop 38 time: 2184 s, i.e. 00:36:24 hms\n",
      "Loop 39 time: 2233 s, i.e. 00:37:13 hms\n",
      "Loop 40 time: 1959 s, i.e. 00:32:39 hms\n",
      "Loop 41 time: 2011 s, i.e. 00:33:31 hms\n",
      "Loop 42 time: 2037 s, i.e. 00:33:57 hms\n",
      "Loop 43 time: 2052 s, i.e. 00:34:12 hms\n",
      "Loop 44 time: 2113 s, i.e. 00:35:13 hms\n",
      "Loop 45 time: 2091 s, i.e. 00:34:51 hms\n",
      "Loop 46 time: 2122 s, i.e. 00:35:22 hms\n",
      "Loop 47 time: 2149 s, i.e. 00:35:49 hms\n",
      "Loop 48 time: 2196 s, i.e. 00:36:36 hms\n",
      "Loop 49 time: 2258 s, i.e. 00:37:38 hms\n",
      "Loop 50 time: 1954 s, i.e. 00:32:34 hms\n",
      "Loop 51 time: 2024 s, i.e. 00:33:44 hms\n",
      "Loop 52 time: 2101 s, i.e. 00:35:01 hms\n",
      "Loop 53 time: 2104 s, i.e. 00:35:04 hms\n",
      "Loop 54 time: 2150 s, i.e. 00:35:50 hms\n",
      "Loop 55 time: 2187 s, i.e. 00:36:27 hms\n",
      "Loop 56 time: 2146 s, i.e. 00:35:46 hms\n",
      "Loop 57 time: 2120 s, i.e. 00:35:20 hms\n",
      "Loop 58 time: 2234 s, i.e. 00:37:14 hms\n",
      "Loop 59 time: 2187 s, i.e. 00:36:27 hms\n",
      "Loop 60 time: 1975 s, i.e. 00:32:55 hms\n",
      "Loop 61 time: 2050 s, i.e. 00:34:10 hms\n",
      "Loop 62 time: 2069 s, i.e. 00:34:29 hms\n",
      "Loop 63 time: 2039 s, i.e. 00:33:59 hms\n",
      "Loop 64 time: 2118 s, i.e. 00:35:18 hms\n",
      "Loop 65 time: 2119 s, i.e. 00:35:19 hms\n",
      "Loop 66 time: 2113 s, i.e. 00:35:13 hms\n",
      "Loop 67 time: 2195 s, i.e. 00:36:35 hms\n",
      "Loop 68 time: 2187 s, i.e. 00:36:27 hms\n",
      "Loop 69 time: 2159 s, i.e. 00:35:59 hms\n",
      "Loop 70 time: 1944 s, i.e. 00:32:24 hms\n",
      "Loop 71 time: 2009 s, i.e. 00:33:29 hms\n",
      "Loop 72 time: 2056 s, i.e. 00:34:16 hms\n",
      "Loop 73 time: 2107 s, i.e. 00:35:07 hms\n",
      "Loop 74 time: 2232 s, i.e. 00:37:12 hms\n",
      "Loop 75 time: 2212 s, i.e. 00:36:52 hms\n",
      "Loop 76 time: 2257 s, i.e. 00:37:37 hms\n",
      "Loop 77 time: 2306 s, i.e. 00:38:26 hms\n",
      "Loop 78 time: 2307 s, i.e. 00:38:27 hms\n",
      "Loop 79 time: 2128 s, i.e. 00:35:28 hms\n",
      "\n",
      "Total process time for 3.75e+11 sets of cells and 4.11e+12 quads of particles: 17687 s, i.e. 04:54:47 hms\n",
      "We tried 1.22e+09 pairs, 1.59e+10 triples and 4.83e+11 quads of cells.\n",
      "Of these, we accepted 7.94e+08 pairs, 1.21e+10 triples and 3.75e+11 quads of cells.\n",
      "We sampled 5.14e+09 pairs, 1.03e+11 triples and 4.11e+12 quads of particles.\n",
      "Of these, we have integral contributions from 1.43e+09 pairs, 8.07e+09 triples and 1.46e+11 quads of particles.\n",
      "Cell acceptance ratios are 0.652 for pairs, 0.760 for triples and 0.776 for quads.\n",
      "Acceptance ratios are 0.279 for pairs, 0.079 for triples and 0.035 for quads.\n",
      "Average of 2009.53 pairs accepted per primary particle.\n",
      "\n",
      "\n",
      "Trial speed: 2.32e+07 quads per core per second\n",
      "Acceptance speed: 7.42e+06 quads per core per second\n",
      "Printed jackknife integrals to file in the out/CovMatricesJack/ directory\n",
      "# user CPU time used: 175013 \n",
      "# system CPU time used: 10 \n",
      "# maximum resident set size: 1440748 \n",
      "# integral shared memory size: 0 \n",
      "# integral unshared data size: 0 \n",
      "# integral unshared stack size: 0 \n",
      "# page reclaims (soft page faults): 429865 \n",
      "# page faults (hard page faults): 18 \n",
      "# swaps: 0 \n",
      "# block input operations: 416 \n",
      "# block output operations: 0 \n",
      "# IPC messages sent: 0 \n",
      "# IPC messages received: 0 \n",
      "# signals received: 0 \n",
      "# voluntary context switches: 1900 \n",
      "# involuntary context switches: 72116 \n",
      "The C++ code finished succesfully\n",
      "2024-05-01 12:36:11.602250\n",
      "Starting post-processing\n",
      "Loading correlation function jackknife estimates from out/xi_jack/xi_jack_n45_m100_j60_11.dat\n",
      "Loading jackknife weights from out/weights/jackknife_weights_n45_m100_j60_11.dat\n",
      "Computing data covariance matrix\n",
      "Loading mu bin Legendre factors from out/weights/mu_bin_legendre_factors_m100_l4.txt\n",
      "Loading best estimate of jackknife covariance matrix\n",
      "Optimizing for the shot-noise rescaling parameter\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -70779206658080.171875\n",
      "         Iterations: 66\n",
      "         Function evaluations: 138\n",
      "Optimization complete - optimal rescaling parameter is 1.067648\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The full covariance is not positive definite - insufficient convergence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRascalC\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_cov\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_l\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperiodic_boxsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN4\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_loops\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloops_per_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloops_per_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpycorr_allcounts_11\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallcounts_rebinned_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mxi_table_11\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallcounts_rebinned_xi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mno_data_galaxies1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgalaxies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mposition_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrdd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mrandoms_positions1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mget_rdd_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandoms_subset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandoms_weights1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandoms_subset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWEIGHT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandoms_samples1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandoms_subset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJACK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnormalize_wcounts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/desi/users/mrash/RascalC/RascalC/interface.py:463\u001b[0m, in \u001b[0;36mrun_cov\u001b[0;34m(mode, nthread, N2, N3, N4, n_loops, loops_per_sample, out_dir, tmp_dir, randoms_positions1, randoms_weights1, pycorr_allcounts_11, xi_table_11, position_type, xi_table_12, xi_table_22, xi_cut_s, pycorr_allcounts_12, pycorr_allcounts_22, normalize_wcounts, no_data_galaxies1, no_data_galaxies2, randoms_samples1, randoms_positions2, randoms_weights2, randoms_samples2, max_l, boxsize, skip_s_bins, skip_l, shot_noise_rescaling1, shot_noise_rescaling2, sampling_grid_size, coordinate_scaling, verbose)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jackknife:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpost_process\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegendre_mix_jackknife\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m post_process_legendre_mix_jackknife\n\u001b[0;32m--> 463\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpost_process_legendre_mix_jackknife\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_jack_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjackknife_weights_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mu_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_s_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_and_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpost_process\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegendre\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m post_process_legendre\n",
      "File \u001b[0;32m/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/legendre_mix_jackknife.py:88\u001b[0m, in \u001b[0;36mpost_process_legendre_mix_jackknife\u001b[0;34m(jackknife_file, weight_dir, file_root, m, max_l, outdir, skip_r_bins, skip_l, tracer, print_function)\u001b[0m\n\u001b[1;32m     85\u001b[0m check_eigval_convergence(c2f, c4f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Check positive definiteness\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43mcheck_positive_definiteness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_cov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Compute full precision matrix\u001b[39;00m\n\u001b[1;32m     91\u001b[0m print_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing the full precision matrix estimate:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/utils.py:50\u001b[0m, in \u001b[0;36mcheck_positive_definiteness\u001b[0;34m(full_cov)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_positive_definiteness\u001b[39m(full_cov: np\u001b[38;5;241m.\u001b[39mndarray[\u001b[38;5;28mfloat\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvalsh(full_cov) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe full covariance is not positive definite - insufficient convergence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The full covariance is not positive definite - insufficient convergence"
     ]
    }
   ],
   "source": [
    "from RascalC import run_cov\n",
    "results = run_cov(mode = mode, max_l = max_l, boxsize = periodic_boxsize,\n",
    "                  nthread = n_threads, N2 = N2, N3 = N3, N4 = N4, n_loops = n_loops, loops_per_sample = loops_per_sample,\n",
    "                  pycorr_allcounts_11 = allcounts_rebinned_cov,\n",
    "                  xi_table_11 = allcounts_rebinned_xi,\n",
    "                  no_data_galaxies1 = len(galaxies),\n",
    "                  position_type = \"rdd\",\n",
    "                  randoms_positions1 = get_rdd_positions(randoms_subset), randoms_weights1 = randoms_subset[\"WEIGHT\"], randoms_samples1 = randoms_subset[\"JACK\"],\n",
    "                  normalize_wcounts = True,\n",
    "                  out_dir = outdir, tmp_dir = tmpdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above ran well, most of the job is basically done, there are some additional explanations in the end.\n",
    "\n",
    "It is quite possible that the convergence was insufficient above or the process timed out, instructions for that case follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary directory can (and should) be removed safely in any case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"rm -rf {tmpdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case of interruption or error\n",
    "\n",
    "It may be useful to run the post-processing separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading correlation function jackknife estimates from out/xi_jack/xi_jack_n45_m100_j60_11.dat\n",
      "Loading jackknife weights from out/weights/jackknife_weights_n45_m100_j60_11.dat\n",
      "Computing data covariance matrix\n",
      "Loading mu bin Legendre factors from out/weights/mu_bin_legendre_factors_m100_l4.txt\n",
      "Loading best estimate of jackknife covariance matrix\n",
      "Optimizing for the shot-noise rescaling parameter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/utils.py:46: UserWarning: Jackknife 4-point covariance matrix has not converged properly via the eigenvalue test. Min eigenvalue of C4 = -1.76e-05, min eigenvalue of C2 = 1.29e-08\n",
      "  warn(f\"{kind}4-point covariance matrix has not converged properly via the eigenvalue test. Min eigenvalue of C4 = {min(eig_c4):.2e}, min eigenvalue of C2 = {min(eig_c2):.2e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -70779206658080.171875\n",
      "         Iterations: 66\n",
      "         Function evaluations: 138\n",
      "Optimization complete - optimal rescaling parameter is 1.067648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/utils.py:46: UserWarning: Full 4-point covariance matrix has not converged properly via the eigenvalue test. Min eigenvalue of C4 = -2.33e-05, min eigenvalue of C2 = 1.73e-08\n",
      "  warn(f\"{kind}4-point covariance matrix has not converged properly via the eigenvalue test. Min eigenvalue of C4 = {min(eig_c4):.2e}, min eigenvalue of C2 = {min(eig_c2):.2e}\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The full covariance is not positive definite - insufficient convergence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_mu_orig \u001b[38;5;241m=\u001b[39m allcounts_rebinned_cov\u001b[38;5;241m.\u001b[39mwrap()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m n_s_bins \u001b[38;5;241m=\u001b[39m allcounts_rebinned_cov\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpost_process_legendre_mix_jackknife\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/xi_jack/xi_jack_n\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_s_bins\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_m\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_mu_orig\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_j\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_jack\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_11.dat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mu_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/legendre_mix_jackknife.py:88\u001b[0m, in \u001b[0;36mpost_process_legendre_mix_jackknife\u001b[0;34m(jackknife_file, weight_dir, file_root, m, max_l, outdir, skip_r_bins, skip_l, tracer, print_function)\u001b[0m\n\u001b[1;32m     85\u001b[0m check_eigval_convergence(c2f, c4f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Check positive definiteness\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43mcheck_positive_definiteness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_cov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Compute full precision matrix\u001b[39;00m\n\u001b[1;32m     91\u001b[0m print_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing the full precision matrix estimate:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/global/common/software/desi/users/mrash/RascalC/RascalC/post_process/utils.py:50\u001b[0m, in \u001b[0;36mcheck_positive_definiteness\u001b[0;34m(full_cov)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_positive_definiteness\u001b[39m(full_cov: np\u001b[38;5;241m.\u001b[39mndarray[\u001b[38;5;28mfloat\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvalsh(full_cov) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe full covariance is not positive definite - insufficient convergence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The full covariance is not positive definite - insufficient convergence"
     ]
    }
   ],
   "source": [
    "from RascalC.post_process.legendre_mix_jackknife import post_process_legendre_mix_jackknife\n",
    "n_mu_orig = allcounts_rebinned_cov.wrap().shape[1]\n",
    "n_s_bins = allcounts_rebinned_cov.shape[0]\n",
    "post_process_legendre_mix_jackknife(f\"{outdir}/xi_jack/xi_jack_n{n_s_bins}_m{n_mu_orig}_j{n_jack}_11.dat\", f\"{outdir}/weights\", outdir, n_mu_orig, max_l, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do with insufficient convergence\n",
    "\n",
    "* run longer (list parameters)\n",
    "* reduce the number of bins:\n",
    "  * discard lower separation bins (names of parameters for that)\n",
    "  * discard higher multipole moments (names of parameters for that too)\n",
    "  * change the bin configuration more generally and re-launch the main covariance computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you have converged and post-processed results\n",
    "\n",
    "Everything returned by post-processing script is already saved in a compressed Numpy file in the output directory and can be loaded again as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(f\"{outdir}/Rescaled_Covariance_Matrices_Legendre_Jackknife_n{n_s_bins}_l{max_l}_j{n_jack}.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal shot-noise rescaling value can be accessed as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"shot_noise_rescaling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final covariance matrix is stored as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"full_theory_covariance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For historical reasons, its ordering is (radial bin, multipole) with only even multipoles included.\n",
    "\n",
    "We provide a utility function for transposing it to (multipole, radial bin) ordering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RascalC.cov_utils import convert_cov_legendre\n",
    "full_cov = convert_cov_legendre(results[\"full_theory_covariance\"], max_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
